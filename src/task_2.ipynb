{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model1\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data \n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch: 1 total_correct: 6792 loss: 45.04048562049866\n",
      "epoch: 2 total_correct: 9051 loss: 42.98218750953674\n",
      "epoch: 3 total_correct: 10870 loss: 42.17493200302124\n",
      "epoch: 4 total_correct: 10346 loss: 42.428473711013794\n",
      "Training Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  cat   ship  ship  plane frog  frog  car   frog  cat   car   plane truck dog   horse truck ship  dog   horse ship  frog  horse plane deer  truck dog   bird  deer  plane truck frog  frog  dog   deer  dog   truck bird  deer  car   truck dog   deer  frog  dog   frog  plane truck cat   truck horse frog  truck ship  plane cat   ship  ship  horse horse deer  frog  horse cat   frog  cat   frog  bird  car   bird  cat   horse bird  frog  ship  ship  plane bird  truck cat   cat   ship  ship  car   car   horse bird  dog   bird  horse ship  truck plane cat   ship  frog  deer  frog  frog  plane plane horse deer  dog   frog  cat   car   car   cat   frog  ship  horse deer  plane frog  bird  car   cat   plane deer  bird  horse ship  cat   car   bird  ship  plane ship  cat   dog   bird  deer  car   ship  truck car   bird  truck horse bird  truck frog  dog   frog  cat   ship  horse frog  bird  dog   bird  ship  truck frog  plane plane dog   bird  truck dog   deer  bird  car   frog  frog  ship  deer  ship  deer  dog   plane truck truck truck ship  truck truck cat   horse dog   plane plane dog   bird  bird  cat   ship  frog  cat   deer  plane dog   ship  plane car   horse bird  ship  ship  horse ship  dog   car   ship  horse car   cat   plane dog   horse truck horse deer  dog   truck ship  plane horse truck ship  bird  horse frog  truck deer  cat   truck frog  deer  horse frog  dog   car   dog   ship  ship  plane deer  plane dog   dog   car   car   ship  truck plane cat   car   truck bird  bird  dog   cat   truck truck deer  plane cat   plane plane truck ship  car   dog   horse plane ship  bird  deer  horse plane bird  cat   frog  cat   ship  dog   plane cat   deer  cat   truck plane frog  car   plane truck car   plane horse truck car   bird  frog  truck cat   deer  frog  plane plane frog  frog  frog  cat   bird  frog  car   ship  bird  car   frog  ship  frog  ship  plane deer  plane horse horse dog   dog   cat   dog   bird  cat   deer  car   horse dog   deer  frog  car   truck cat   frog  frog  truck cat   ship  plane horse bird  frog  bird  dog   ship  dog   deer  frog  ship  truck truck car   plane bird  bird  horse cat   bird  ship  plane truck dog   ship  car   truck deer  car   cat   ship  car   deer  horse truck deer  bird  horse plane horse plane frog  frog  truck plane truck bird  ship  horse bird  bird  dog   car   bird  frog  bird  truck frog  bird  cat   plane cat   truck ship  horse ship  ship  deer  plane car   ship  bird  horse truck cat   frog  car   truck plane horse cat   horse deer  dog   plane plane bird  truck cat   deer  plane frog  bird  dog   cat   horse cat   horse bird  dog   cat   car   car   deer  truck truck dog   horse dog   plane bird  bird  bird  truck horse cat   truck deer  cat   dog   deer  frog  dog   frog  car   deer  cat   deer  deer  cat   horse ship  cat   horse ship  plane dog   horse frog  plane dog   deer  ship  frog  ship  dog   dog   truck truck truck dog   plane car   plane ship  car   car   ship  plane bird  bird  plane deer  frog  dog   deer  truck deer  horse truck truck deer  dog   frog  frog  car   dog   cat   ship  truck dog   ship  dog   horse plane horse plane dog   plane plane deer  frog  truck plane truck dog   frog  frog  frog  bird  truck plane car   horse frog  horse dog   truck car   frog  bird  dog   dog   dog   ship  dog   truck deer  frog  deer  cat   bird  plane horse frog  bird  bird  cat   truck horse truck bird  frog  horse car   cat   frog  frog  ship  truck horse dog   deer  plane ship  deer  plane truck cat   deer  ship  truck frog  truck bird  frog  car   deer  horse cat   dog   cat   ship  dog   plane bird  car   frog  deer  cat   cat   truck frog  truck ship  ship  dog   ship  frog  frog  bird  car   horse horse car   bird  horse truck truck deer  deer  car   bird  dog   frog  ship  horse frog  ship  cat   plane dog   dog   cat   plane horse truck car   cat   deer  deer  dog   cat   truck dog   frog  truck bird  car   car   deer  car   truck deer  horse frog  cat   ship  truck plane car   cat   frog  cat   frog  cat   bird  plane cat   car   plane dog   truck frog  deer  ship  truck frog  truck frog  cat   plane cat   bird  bird  horse ship  cat   ship  bird  horse dog   horse bird  deer  ship  horse deer  bird  truck ship  ship  frog  ship  ship  horse deer  cat   cat   ship  deer  truck deer  ship  ship  car   ship  bird  car   cat   frog  dog   deer  bird  horse truck truck deer  car   deer  car   cat   bird  horse plane horse truck horse frog  frog  bird  dog   truck bird  truck car   bird  bird  frog  ship  bird  car   cat   frog  frog  plane car   bird  horse plane dog   deer  frog  car   frog  deer  plane bird  bird  frog  plane dog   truck car   horse frog  horse plane cat   truck frog  ship  cat   plane cat   deer  horse horse car   deer  horse bird  horse car   deer  horse deer  deer  ship  deer  horse horse dog   cat   horse bird  plane ship  truck dog   ship  cat   frog  bird  plane ship  horse cat   horse frog  dog   cat   car   cat   bird  bird  dog   deer  car   bird  truck bird  horse plane horse bird  car   cat   bird  plane bird  deer  horse truck ship  truck plane horse horse plane horse ship  deer  frog  cat   cat   plane car   cat   horse plane car   cat   car   deer  bird  cat   ship  deer  bird  cat   horse ship  deer  cat   plane truck plane plane car   plane deer  deer  frog  horse frog  car   car   cat   horse cat   dog   bird  frog  frog  dog   ship  horse car   frog  ship  ship  dog   cat   plane deer  plane car   cat   ship  ship  plane frog  truck truck truck dog   dog   ship  frog  plane plane deer  bird  cat   bird  horse bird  bird  dog   truck ship  truck car   horse deer  plane cat   plane car   cat   ship  cat   truck frog  car   deer  horse plane cat   horse ship  truck car   car   frog  frog  frog  frog  truck car   truck truck deer  bird  car   horse plane frog  ship  car   truck bird  truck plane deer  horse ship  cat   car   bird  plane car   dog   ship  deer  frog  cat   ship  car   cat   ship  dog   plane ship  deer  ship  car   car   ship  truck frog  plane ship  frog  car   cat   deer  car   frog  plane dog   car   car   plane plane cat   dog   plane plane frog  frog  cat   cat   frog  cat   frog  frog  plane horse bird  bird  horse dog   dog   bird  ship  dog   bird  car   car   deer  cat   bird  plane cat   car   dog   cat   horse frog  ship  truck car   frog  deer  truck cat   truck plane truck frog  cat   frog  plane horse cat   ship  plane plane plane frog  frog  frog  truck bird  dog   deer  deer  frog  cat   frog  plane ship  frog  plane frog  bird  horse dog   car   bird  horse ship  ship  plane truck deer  truck horse bird  plane bird  ship  cat   ship  truck car   dog   dog   deer  horse dog   cat   ship  cat   cat   frog  bird  ship  deer  cat   horse car   bird  deer  car   frog  truck plane dog   ship  frog  car   ship  frog  car   deer  bird  frog  bird  horse bird  bird  plane ship  frog  truck car   horse car   ship  ship  plane horse cat   ship  plane cat   deer  cat   horse horse truck bird  cat   car   truck car   truck frog  cat   cat   cat   car   plane frog  car   deer  car   plane plane car   car   frog  dog   deer  frog  bird  plane horse truck ship  horse bird  plane frog  ship  car   deer  cat   horse plane frog  car   ship  dog   horse ship  deer  ship  cat   truck truck truck ship  horse frog  frog  cat   dog   car   dog   truck car   deer  car   dog   horse plane car   dog   bird  plane ship  ship  dog   frog  horse cat   bird  deer  horse bird  dog   ship  bird  deer  truck bird  car   ship  car   truck ship  ship  ship  truck plane deer  cat   cat   car   ship  deer  frog  cat   cat   dog   bird  bird  ship  cat   ship  truck dog   ship  truck ship  truck car   frog  dog   truck deer  deer  ship  plane horse bird  truck horse deer  car   frog  deer  deer  truck car   bird  dog   frog  plane ship  frog  car   truck deer  dog   truck dog   plane horse bird  plane plane deer  bird  frog  frog  dog   dog   bird  ship  car   horse cat   car   deer  dog   frog  dog   car   deer  horse plane truck deer  cat   ship  bird  ship  deer  horse bird  cat   car   dog   bird  truck ship  truck horse truck dog   car   deer  plane ship  bird  cat   ship  truck car   car   cat   bird  deer  truck cat   car   horse deer  frog  bird  ship  truck dog   cat   truck dog   dog   frog  horse bird  deer  frog  cat   car   plane horse bird  dog   deer  horse frog  car   car   truck ship  car   plane car   cat   car   car   car   horse cat   truck frog  ship  deer  frog  ship  deer  truck deer  horse truck horse frog  ship  deer  truck horse plane car   frog  car   dog   truck plane deer  cat   deer  car   cat   plane ship  deer  frog  bird  bird  frog  dog   cat   frog  bird  car   car   ship  frog  plane deer  plane car   truck horse car   cat   horse horse ship  horse horse cat   truck horse horse horse bird  car   bird  ship  frog  deer  plane horse truck ship  frog  ship  deer  truck car   horse bird  bird  ship  dog   ship  car   bird  bird  deer  car   bird  dog   bird  ship  car   ship  car   ship  frog  plane bird  deer  car   cat   frog  horse horse deer  deer  cat   cat   deer  dog   bird  deer  cat   horse ship  deer  deer  deer  dog   deer  cat   bird  ship  deer  dog   dog   deer  car   deer  bird  dog   car   frog  deer  cat   deer  deer  plane ship  ship  deer  dog   horse dog   frog  truck car   frog  horse bird  plane car   deer  dog   frog  plane plane bird  horse dog   frog  plane frog  bird  truck car   horse horse dog   bird  dog   frog  deer  car   deer  cat   cat   cat   plane cat   dog   dog   ship  truck horse cat   car   cat   cat   cat   deer  deer  bird  cat   cat   ship  car   horse horse plane horse deer  dog   car   deer  bird  deer  cat   truck truck deer  truck truck car   ship  car   frog  horse dog   dog   deer  truck horse frog  dog   truck bird  deer  plane horse ship  dog   dog   plane plane truck truck ship  bird  dog   deer  ship  cat   frog  cat   frog  plane frog  frog  frog  truck frog  frog  ship  frog  bird  deer  dog   ship  car   bird  horse frog  dog   horse ship  car   ship  plane ship  frog  truck bird  ship  truck deer  plane truck deer  truck dog   horse dog   dog   truck dog   cat   plane car   truck horse bird  deer  car   plane ship  plane cat   car   horse plane plane deer  ship  frog  bird  deer  plane plane truck plane ship  deer  dog   truck cat   truck plane dog   frog  dog   plane car   deer  ship  car   plane dog   bird  car   plane bird  ship  car   dog   frog  horse horse bird  frog  bird  dog   plane car   deer  bird  dog   deer  frog  bird  bird  car   horse bird  ship  dog   dog   cat   plane deer  ship  cat   horse frog  cat   ship  car   plane car   cat   cat   plane horse deer  truck dog   cat   frog  plane car   deer  deer  deer  deer  bird  bird  dog   ship  car   dog   truck ship  car   car   dog   cat   truck truck horse frog  dog   plane ship  deer  horse plane truck bird  ship  deer  horse car   cat   truck frog  ship  truck plane deer  truck frog  horse ship  truck deer  ship  truck horse bird  dog   cat   horse car   plane bird  truck dog   dog   ship  dog   deer  bird  ship  cat   dog   dog   horse horse ship  frog  bird  ship  bird  cat   dog   frog  ship  plane bird  cat   horse plane car   truck car   cat   horse dog   ship  cat   bird  truck frog  ship  frog  truck cat   ship  truck ship  plane horse ship  dog   plane plane car   cat   truck car   dog   cat   deer  deer  plane truck truck truck truck ship  bird  deer  bird  bird  dog   car   truck car   plane truck deer  bird  car   frog  plane cat   horse frog  cat   car   ship  frog  dog   horse bird  ship  deer  deer  ship  cat   dog   plane dog   horse deer  deer  bird  bird  horse cat   frog  plane bird  horse frog  bird  cat   plane horse horse ship  car   car   deer  frog  plane frog  frog  dog   dog   frog  cat   truck cat   frog  ship  horse frog  deer  truck dog   frog  deer  car   frog  cat   ship  bird  cat   truck ship  dog   car   dog   deer  dog   horse dog   horse ship  truck car   horse bird  dog   frog  ship  deer  frog  dog   cat   truck truck ship  dog   dog   frog  deer  dog   truck horse cat   deer  car   deer  bird  cat   frog  dog   dog   bird  ship  plane plane car   ship  cat   car   cat   dog   ship  cat   ship  dog   ship  frog  cat   dog   dog   dog   plane truck dog   dog   horse car   ship  bird  bird  horse cat   deer  bird  truck frog  bird  bird  deer  cat   plane bird  plane car   cat   bird  bird  horse plane car   plane horse horse bird  plane car   frog  dog   plane bird  bird  plane car   bird  frog  plane car   frog  frog  dog   cat   deer  plane plane truck car   plane bird  dog   truck horse ship  frog  deer  frog  plane bird  plane car   truck bird  deer  truck plane horse bird  cat   deer  ship  plane bird  frog  ship  truck horse car   truck cat   horse bird  horse truck frog  truck dog   horse ship  dog   truck ship  cat   truck ship  plane dog   dog   horse car   bird  plane horse dog   ship  bird  bird  dog   cat   truck cat   car   truck cat   car   deer  cat   deer  deer  truck plane truck dog   truck bird  truck deer  plane bird  ship  deer  ship  frog  ship  bird  plane dog   truck frog  truck dog   car   cat   deer  deer  bird  horse bird  deer  deer  plane bird  ship  deer  dog   car   bird  frog  ship  car   horse bird  ship  horse deer  cat   cat   plane cat   horse bird  dog   frog  car   horse truck plane bird  cat   truck ship  truck dog   plane plane horse frog  cat   cat   ship  car   deer  plane car   dog   deer  cat   bird  frog  plane ship  ship  frog  cat   cat   bird  truck horse dog   car   frog  plane dog   truck truck deer  dog   truck deer  ship  cat   cat   bird  dog   car   truck dog   dog   ship  car   ship  truck horse plane frog  cat   bird  plane bird  frog  truck cat   truck car   frog  frog  horse bird  frog  cat   bird  dog   dog   bird  horse dog   bird  plane ship  plane horse horse car   horse deer  plane bird  bird  frog  car   dog   truck horse frog  bird  horse plane dog   frog  plane car   car   ship  deer  dog   cat   car   bird  deer  ship  truck ship  car   horse bird  horse bird  cat   bird  frog  horse truck deer  plane car   plane deer  dog   plane ship  plane horse frog  car   plane ship  dog   truck bird  dog   deer  deer  truck plane frog  car   bird  dog   car   frog  horse car   dog   ship  ship  plane cat   truck deer  plane cat   deer  truck bird  deer  cat   plane frog  deer  dog   frog  frog  horse ship  deer  ship  ship  cat   bird  ship  plane bird  dog   frog  ship  horse ship  truck truck plane frog  frog  ship  car   car   horse deer  deer  bird  cat   frog  truck frog  bird  deer  car   ship  bird  cat   car   frog  ship  frog  ship  dog   truck plane car   plane bird  truck bird  truck plane truck horse ship  dog   plane frog  frog  ship  car   frog  dog   ship  horse truck bird  car   frog  horse dog   frog  cat   plane truck ship  truck dog   truck truck truck cat   frog \n",
      "Accuracy of the network on the 10000 test images: 19 %\n",
      "Accuracy of the network on the 10000 test images: 19 %\n",
      "Accuracy for class: plane is 0.0 %\n",
      "Accuracy for class: car   is 0.0 %\n",
      "Accuracy for class: bird  is 4.8 %\n",
      "Accuracy for class: cat   is 0.0 %\n",
      "Accuracy for class: deer  is 0.7 %\n",
      "Accuracy for class: dog   is 19.8 %\n",
      "Accuracy for class: frog  is 64.6 %\n",
      "Accuracy for class: horse is 30.2 %\n",
      "Accuracy for class: ship  is 0.0 %\n",
      "Accuracy for class: truck is 69.9 %\n"
     ]
    }
   ],
   "source": [
    "PATH ='./cifarmodel1.pth'\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "#Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])\n",
    "\n",
    "#Creating the Datasets\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                    download=True, transform=test_transforms)\n",
    "\n",
    "#Data Loaders\n",
    "batch_size = 2500\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "model = Model1()\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "except:\n",
    "    print(\"File does not exist, unable to load state dictionary from PATH\")\n",
    "\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas= (0.9, 0.999), eps = 1e-08, weight_decay=0)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(4):\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        #get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(inputs).cuda()\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += outputs.argmax(dim=1).eq(labels).sum().item()\n",
    "    print('epoch:', epoch + 1, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "print(\"Training Complete\")\n",
    "\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images).cuda()\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images).cuda()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "File does not exist, unable to load state dictionary from PATH\n",
      "epoch: 1 total_correct: 6734 loss: 45.90318751335144\n",
      "epoch: 2 total_correct: 6173 loss: 45.30836486816406\n",
      "epoch: 3 total_correct: 7873 loss: 44.53563451766968\n",
      "epoch: 4 total_correct: 9188 loss: 43.632702350616455\n",
      "Training Complete\n",
      "Finished Training\n",
      "GroundTruth:  cat   ship  ship  plane\n",
      "Accuracy of the network on the 10000 test images: 12 %\n",
      "Accuracy of the network on the 10000 test images: 12 %\n",
      "Accuracy for class: plane is 0.0 %\n",
      "Accuracy for class: car   is 0.3 %\n",
      "Accuracy for class: bird  is 0.0 %\n",
      "Accuracy for class: cat   is 5.5 %\n",
      "Accuracy for class: deer  is 29.8 %\n",
      "Accuracy for class: dog   is 15.9 %\n",
      "Accuracy for class: frog  is 50.8 %\n",
      "Accuracy for class: horse is 19.3 %\n",
      "Accuracy for class: ship  is 3.3 %\n",
      "Accuracy for class: truck is 0.0 %\n"
     ]
    }
   ],
   "source": [
    "PATH ='./cifarmodel2.pth'\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "#Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                            transforms.GaussianBlur(kernel_size = (3,3)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            transforms.RandomErasing(0.2),\n",
    "                            transforms.RandomRotation(45),\n",
    "                            transforms.RandomHorizontalFlip(25),\n",
    "                            transforms.RandomVerticalFlip(25),\n",
    "                                    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])\n",
    "\n",
    "#Creating the Datasets\n",
    "trainset = datasets.CIFAR10(root='./model2/data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "testset = datasets.CIFAR10(root='./model2/data', train=False,\n",
    "                                    download=True, transform=test_transforms)\n",
    "\n",
    "#Data Loaders\n",
    "batch_size = 2500\n",
    "\n",
    "trainloader2 = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "testloader2 = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "model1 = Model1()\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "except:\n",
    "    print(\"File does not exist, unable to load state dictionary from PATH\")\n",
    "\n",
    "model1.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas= (0.9, 0.999), eps = 1e-08, weight_decay=0)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(4):\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(trainloader2, 0):\n",
    "        \n",
    "        #get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(inputs).cuda()\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += outputs.argmax(dim=1).eq(labels).sum().item()\n",
    "    print('epoch:', epoch + 1, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "print(\"Training Complete\")\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "dataiter2 = iter(testloader2)\n",
    "images, labels = next(dataiter2)\n",
    "\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader2:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images).cuda()\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader2:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images).cuda()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "File does not exist, unable to load state dictionary from PATH\n",
      "epoch: 1 total_correct: 9277 loss: 43.269787073135376\n",
      "epoch: 2 total_correct: 8242 loss: 43.07383751869202\n",
      "epoch: 3 total_correct: 8912 loss: 43.14526724815369\n",
      "epoch: 4 total_correct: 7923 loss: 45.57160711288452\n",
      "epoch: 5 total_correct: 8851 loss: 44.39819121360779\n",
      "epoch: 6 total_correct: 9368 loss: 43.65787625312805\n",
      "epoch: 7 total_correct: 9380 loss: 43.671916246414185\n",
      "epoch: 8 total_correct: 9307 loss: 43.40334892272949\n",
      "epoch: 9 total_correct: 9201 loss: 43.499711990356445\n",
      "epoch: 10 total_correct: 9815 loss: 43.92550802230835\n",
      "epoch: 11 total_correct: 8380 loss: 44.121381759643555\n",
      "epoch: 12 total_correct: 7624 loss: 44.506420612335205\n",
      "epoch: 13 total_correct: 8181 loss: 44.615854263305664\n",
      "epoch: 14 total_correct: 9082 loss: 43.88927388191223\n",
      "epoch: 15 total_correct: 8903 loss: 43.4867057800293\n",
      "epoch: 16 total_correct: 9877 loss: 43.02157998085022\n",
      "epoch: 17 total_correct: 10204 loss: 43.48625159263611\n",
      "epoch: 18 total_correct: 9581 loss: 43.76691484451294\n",
      "epoch: 19 total_correct: 8600 loss: 44.10195469856262\n",
      "epoch: 20 total_correct: 8209 loss: 45.2218074798584\n",
      "epoch: 21 total_correct: 7944 loss: 44.39528703689575\n",
      "epoch: 22 total_correct: 7481 loss: 45.36288619041443\n",
      "epoch: 23 total_correct: 7234 loss: 45.81605672836304\n",
      "epoch: 24 total_correct: 7523 loss: 45.025816679000854\n",
      "epoch: 25 total_correct: 7461 loss: 44.59880256652832\n",
      "epoch: 26 total_correct: 7160 loss: 44.85784411430359\n",
      "epoch: 27 total_correct: 6845 loss: 45.137890338897705\n",
      "epoch: 28 total_correct: 7067 loss: 44.9739465713501\n",
      "epoch: 29 total_correct: 7158 loss: 44.8668270111084\n",
      "epoch: 30 total_correct: 7216 loss: 44.845094203948975\n",
      "epoch: 31 total_correct: 7236 loss: 44.756917238235474\n",
      "epoch: 32 total_correct: 7483 loss: 44.769808769226074\n",
      "epoch: 33 total_correct: 7334 loss: 44.68677115440369\n",
      "epoch: 34 total_correct: 6821 loss: 45.00206685066223\n",
      "epoch: 35 total_correct: 6852 loss: 45.176597356796265\n",
      "epoch: 36 total_correct: 7780 loss: 44.79999041557312\n",
      "epoch: 37 total_correct: 8004 loss: 45.43959712982178\n",
      "epoch: 38 total_correct: 7921 loss: 44.89518451690674\n",
      "epoch: 39 total_correct: 7362 loss: 44.494709491729736\n",
      "epoch: 40 total_correct: 7420 loss: 44.80160474777222\n",
      "epoch: 41 total_correct: 7427 loss: 45.099504709243774\n",
      "epoch: 42 total_correct: 7383 loss: 45.29957723617554\n",
      "epoch: 43 total_correct: 7388 loss: 45.37509751319885\n",
      "epoch: 44 total_correct: 7503 loss: 45.35917925834656\n",
      "epoch: 45 total_correct: 7205 loss: 45.383868932724\n",
      "epoch: 46 total_correct: 7633 loss: 45.22807812690735\n",
      "epoch: 47 total_correct: 7604 loss: 45.253910541534424\n",
      "epoch: 48 total_correct: 7547 loss: 45.28898096084595\n",
      "epoch: 49 total_correct: 7563 loss: 45.18331241607666\n",
      "epoch: 50 total_correct: 7354 loss: 45.296244859695435\n",
      "epoch: 51 total_correct: 7363 loss: 45.189693212509155\n",
      "epoch: 52 total_correct: 7328 loss: 45.050246715545654\n",
      "epoch: 53 total_correct: 7329 loss: 45.41665482521057\n",
      "epoch: 54 total_correct: 7330 loss: 45.493919134140015\n",
      "epoch: 55 total_correct: 7174 loss: 44.945590019226074\n",
      "epoch: 56 total_correct: 6957 loss: 44.90953469276428\n",
      "epoch: 57 total_correct: 6622 loss: 45.3400981426239\n",
      "epoch: 58 total_correct: 6471 loss: 45.61644101142883\n",
      "epoch: 59 total_correct: 6516 loss: 45.5732057094574\n",
      "epoch: 60 total_correct: 6667 loss: 45.3541464805603\n",
      "epoch: 61 total_correct: 6773 loss: 45.135764837265015\n",
      "epoch: 62 total_correct: 6701 loss: 45.11762309074402\n",
      "epoch: 63 total_correct: 6702 loss: 45.344122886657715\n",
      "epoch: 64 total_correct: 6729 loss: 45.548813581466675\n",
      "epoch: 65 total_correct: 6240 loss: 45.821593046188354\n",
      "epoch: 66 total_correct: 6170 loss: 45.960155725479126\n",
      "epoch: 67 total_correct: 5790 loss: 46.17412614822388\n",
      "epoch: 68 total_correct: 5526 loss: 46.47362303733826\n",
      "epoch: 69 total_correct: 5911 loss: 46.10289025306702\n",
      "epoch: 70 total_correct: 6328 loss: 46.28109169006348\n",
      "epoch: 71 total_correct: 6425 loss: 46.839645862579346\n",
      "epoch: 72 total_correct: 6355 loss: 46.71236610412598\n",
      "epoch: 73 total_correct: 6276 loss: 46.20948791503906\n",
      "epoch: 74 total_correct: 6061 loss: 45.8561577796936\n",
      "epoch: 75 total_correct: 5818 loss: 45.800148010253906\n",
      "epoch: 76 total_correct: 5573 loss: 46.0206139087677\n",
      "epoch: 77 total_correct: 5445 loss: 46.137741804122925\n",
      "epoch: 78 total_correct: 5330 loss: 46.261796712875366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m total_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     64\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 65\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader2, \u001b[39m0\u001b[39m):\n\u001b[0;32m     66\u001b[0m     \n\u001b[0;32m     67\u001b[0m     \u001b[39m#get the inputs\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     inputs, labels \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     69\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:1819\u001b[0m, in \u001b[0;36mGaussianBlur.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1811\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   1813\u001b[0m \u001b[39m    img (PIL Image or Tensor): image to be blurred.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[39m    PIL Image or Tensor: Gaussian blurred image\u001b[39;00m\n\u001b[0;32m   1817\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m sigma \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma[\u001b[39m1\u001b[39m])\n\u001b[1;32m-> 1819\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mgaussian_blur(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, [sigma, sigma])\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\functional.py:1386\u001b[0m, in \u001b[0;36mgaussian_blur\u001b[1;34m(img, kernel_size, sigma)\u001b[0m\n\u001b[0;32m   1382\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be PIL Image or Tensor. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(img)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1384\u001b[0m     t_img \u001b[39m=\u001b[39m pil_to_tensor(img)\n\u001b[1;32m-> 1386\u001b[0m output \u001b[39m=\u001b[39m F_t\u001b[39m.\u001b[39;49mgaussian_blur(t_img, kernel_size, sigma)\n\u001b[0;32m   1388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m   1389\u001b[0m     output \u001b[39m=\u001b[39m to_pil_image(output, mode\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mmode)\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:753\u001b[0m, in \u001b[0;36mgaussian_blur\u001b[1;34m(img, kernel_size, sigma)\u001b[0m\n\u001b[0;32m    750\u001b[0m _assert_image_tensor(img)\n\u001b[0;32m    752\u001b[0m dtype \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mdtype \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_floating_point(img) \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mfloat32\n\u001b[1;32m--> 753\u001b[0m kernel \u001b[39m=\u001b[39m _get_gaussian_kernel2d(kernel_size, sigma, dtype\u001b[39m=\u001b[39;49mdtype, device\u001b[39m=\u001b[39;49mimg\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    754\u001b[0m kernel \u001b[39m=\u001b[39m kernel\u001b[39m.\u001b[39mexpand(img\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m], \u001b[39m1\u001b[39m, kernel\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], kernel\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m    756\u001b[0m img, need_cast, need_squeeze, out_dtype \u001b[39m=\u001b[39m _cast_squeeze_in(img, [kernel\u001b[39m.\u001b[39mdtype])\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:741\u001b[0m, in \u001b[0;36m_get_gaussian_kernel2d\u001b[1;34m(kernel_size, sigma, dtype, device)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gaussian_kernel2d\u001b[39m(\n\u001b[0;32m    738\u001b[0m     kernel_size: List[\u001b[39mint\u001b[39m], sigma: List[\u001b[39mfloat\u001b[39m], dtype: torch\u001b[39m.\u001b[39mdtype, device: torch\u001b[39m.\u001b[39mdevice\n\u001b[0;32m    739\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    740\u001b[0m     kernel1d_x \u001b[39m=\u001b[39m _get_gaussian_kernel1d(kernel_size[\u001b[39m0\u001b[39m], sigma[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m--> 741\u001b[0m     kernel1d_y \u001b[39m=\u001b[39m _get_gaussian_kernel1d(kernel_size[\u001b[39m1\u001b[39;49m], sigma[\u001b[39m1\u001b[39;49m])\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    742\u001b[0m     kernel2d \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(kernel1d_y[:, \u001b[39mNone\u001b[39;00m], kernel1d_x[\u001b[39mNone\u001b[39;00m, :])\n\u001b[0;32m    743\u001b[0m     \u001b[39mreturn\u001b[39;00m kernel2d\n",
      "File \u001b[1;32mc:\\Users\\tomj9\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:730\u001b[0m, in \u001b[0;36m_get_gaussian_kernel1d\u001b[1;34m(kernel_size, sigma)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gaussian_kernel1d\u001b[39m(kernel_size: \u001b[39mint\u001b[39m, sigma: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    728\u001b[0m     ksize_half \u001b[39m=\u001b[39m (kernel_size \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m--> 730\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinspace(\u001b[39m-\u001b[39;49mksize_half, ksize_half, steps\u001b[39m=\u001b[39;49mkernel_size)\n\u001b[0;32m    731\u001b[0m     pdf \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (x \u001b[39m/\u001b[39m sigma)\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m))\n\u001b[0;32m    732\u001b[0m     kernel1d \u001b[39m=\u001b[39m pdf \u001b[39m/\u001b[39m pdf\u001b[39m.\u001b[39msum()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PATH ='./cifarmodel3.pth'\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "#Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                            transforms.GaussianBlur(kernel_size = (3,3)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            transforms.RandomErasing(0.2),\n",
    "                            transforms.RandomRotation(45),\n",
    "                            transforms.RandomHorizontalFlip(25),\n",
    "                            transforms.RandomVerticalFlip(25),\n",
    "                                    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])\n",
    "\n",
    "#Creating the Datasets\n",
    "trainset = datasets.CIFAR10(root='./model2/data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "testset = datasets.CIFAR10(root='./model2/data', train=False,\n",
    "                                    download=True, transform=test_transforms)\n",
    "\n",
    "#Data Loaders\n",
    "batch_size = 2500\n",
    "\n",
    "trainloader2 = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "testloader2 = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "model2 = Model1()\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "except:\n",
    "    print(\"File does not exist, unable to load state dictionary from PATH\")\n",
    "\n",
    "model1.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas= (0.9, 0.999), eps = 1e-08, weight_decay=0)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(100):\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(trainloader2, 0):\n",
    "        \n",
    "        #get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(inputs).cuda()\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += outputs.argmax(dim=1).eq(labels).sum().item()\n",
    "    print('epoch:', epoch + 1, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "print(\"Training Complete\")\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "dataiter2 = iter(testloader2)\n",
    "images, labels = next(dataiter2)\n",
    "\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader2:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images).cuda()\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader2:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images).cuda()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stopped after a while because the loss became too great. updated the learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "File does not exist, unable to load state dictionary from PATH\n",
      "epoch: 1 total_correct: 5178 loss: 46.3658664226532\n",
      "epoch: 2 total_correct: 4997 loss: 46.857829093933105\n",
      "epoch: 3 total_correct: 5012 loss: 47.18404507637024\n",
      "epoch: 4 total_correct: 5013 loss: 47.67385005950928\n",
      "Training Complete\n",
      "Finished Training\n",
      "GroundTruth:  cat   ship  ship  plane\n",
      "Accuracy of the network on the 10000 test images: 10 %\n",
      "Accuracy of the network on the 10000 test images: 10 %\n",
      "Accuracy for class: plane is 0.4 %\n",
      "Accuracy for class: car   is 0.0 %\n",
      "Accuracy for class: bird  is 0.0 %\n",
      "Accuracy for class: cat   is 0.0 %\n",
      "Accuracy for class: deer  is 0.0 %\n",
      "Accuracy for class: dog   is 0.0 %\n",
      "Accuracy for class: frog  is 100.0 %\n",
      "Accuracy for class: horse is 0.0 %\n",
      "Accuracy for class: ship  is 0.0 %\n",
      "Accuracy for class: truck is 0.0 %\n"
     ]
    }
   ],
   "source": [
    "PATH ='./cifarmodel4.pth'\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "#Transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                            transforms.GaussianBlur(kernel_size = (3,3)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            transforms.RandomErasing(0.2),\n",
    "                            transforms.RandomRotation(45),\n",
    "                            transforms.RandomHorizontalFlip(25),\n",
    "                            transforms.RandomVerticalFlip(25),\n",
    "                                    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                    ])\n",
    "\n",
    "#Creating the Datasets\n",
    "trainset = datasets.CIFAR10(root='./model2/data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "testset = datasets.CIFAR10(root='./model2/data', train=False,\n",
    "                                    download=True, transform=test_transforms)\n",
    "\n",
    "#Data Loaders\n",
    "batch_size = 2500\n",
    "\n",
    "trainloader2 = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "testloader2 = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                        shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "model4 = Model1()\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "except:\n",
    "    print(\"File does not exist, unable to load state dictionary from PATH\")\n",
    "\n",
    "model1.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01, betas= (0.9, 0.999), eps = 1e-08, weight_decay=0)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(4):\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(trainloader2, 0):\n",
    "        \n",
    "        #get the inputs\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(inputs).cuda()\n",
    "        loss = F.cross_entropy(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_correct += outputs.argmax(dim=1).eq(labels).sum().item()\n",
    "    print('epoch:', epoch + 1, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "print(\"Training Complete\")\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "dataiter2 = iter(testloader2)\n",
    "images, labels = next(dataiter2)\n",
    "\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader2:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images).cuda()\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader2:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images).cuda()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
